# The future of AI is documentation

##

While the inverse is obvious (AI can eventually produce adequate documentation), I will argue that the somewhat counter-intuitive flip-side is infinitely more rewarding (documentation can produce AGI, with G for general).  

*Note on notation: «technical term» ; "metaphorical" ; "Quotation" ; 'Title' ; equivalent/terms*
  
But before I go any further, I want to make clear that this article is intended to be a meeting point of different cultures, including software developers but not only, so I won't assume any familiarity with the notion of documentation, nor any other niche technical concept (a good thing to do in any case, as the first principle of documentation should say). However, for readers who have an inimical relationship to all things technical, I suggest you start with the next section 'AGI as a paradigm shift', which is about the world we live in. While this section browses over certain aspects of the system as a *solution*, mostly theorerical, the following two on the contrary, 'AGI as a paradigm shift' and 'Naturality of the suggested documentation framework', focus on the *problem* to which this solution is an answer, from a political and radical point of view, necessary for the understanding of *how* this solution is indeed a solution, and what's more, a *natural* solution. The last two, 'The documentation process' and 'Return to (generalized) mother', conclude covering necessary material for communicating the concept: a factual description and an historical perspective. This is what this text is intended for: communicating/documenting a concept.

Let's starts with the very concrete concept of «documentation» manufactured by programmers:

> "Documentation is any communicable material that is used to describe, explain or instruct regarding some attributes of an object, system or procedure, such as its parts, assembly, installation, maintenance and use." (<https://www.linfo.org/documentation.html>).

In 1984, while the craft of writting computer code was still in its infancy, one of its "founding parent"—Donald Knuth, in an article called 'Literate Programming'—proposed a development paradigm  which prioritized human communication over computer-readable symbols. He meant that the primary focus and "working material" of the programmer was not "a tangle of code" but "a weave of documentation". It is based on the realization that: "[T]he most important thing about a program is its structural relationships", the pedagogical exposition of which requires a web-like flexible frame, akin to human thinking, as opposed to the rigid tree-like setup of computers. It can be anachronically called «Documentation Driven Development». Unfortunately, it didn't catch on. The industry was in too much of a rush, as industries always are, to go into that time consuming direction. It still is, and always will be (conscious of the importance of documentation, it favors self-documenting code, but misses the crucial points made by Knuth). Which is really too bad because if documentation respects those three criteria: (1) it's open, as in always publicly available and editable, (2) it's elaborate enough, and (3) it's "holistic" in the sense that every piece of documentation targets interoperability with documentation coming from other sources, then this supposedly platitudinous notion derives into more general views on information sharing and "life in common", can be given a philosophical underpinning in «perspectivalism», and in many ways it can *rectify* the current political paradigm.

Mostly, my work has been the assemblage of this idea with others taken from outside the field of computer science (or «algorithmics» as Knuth suggested), to enable the formation of a kind of "super-documentation" which can be useful for humans and useable by computers. I will be using this abstraction as the motive for the next steps:

> Before becoming a program/algorithm, every project is a concept. The proper start to collective endeavor must be the construction of a consensus around the concept and its representation by mathematics-inspired documentation.

As for AGI or Artificial *General* Intelligence, I'll give what mathematicians call a constructive definition: I'll build a system (computer program) which demonstrates what AGI is by being an instance of AGI. In engineering lingo, I could say I will present a «proof-of-concept». It will also be, of course, a conjecture. To avoid trapping the idea into preconceptions, I will simply refer to this particular system as 'our AGI architecture', where AGI should be understood as a general cognitive/information processing system.  

It can be represented as a «dynamical system», meaning as a chain of subsystems/processes all linked together by the fact that the output of one process is the input of the next. Figure 1 sketches a quick overview. In our case, a key subsystem is a concrete implementation of a mathematical model for neural networks proposed by Yuri Manin and Matilde Marcolli (see their publicly available 2020 paper 'Homotopy-theoretic and categorical models of neural information networks'). Their work is inspired by biomimetics and is only secondarily about *artificial* intelligence. Primarily, it is intended to be a model of actual *natural* brains. I suggest we "feed" those Manin & Marcolli cognitive systems with "tailor-made" human-produced data, itself the output of a specific conversation-based documentation-producing protocol I'll introduce below. This AGI should in turn output a "map of its world" ("digested documentation") and a "universal technical language" (it needs one to exist, and it is perfectly designed to create its own). One can think of the map as a big sophisticated diagram, and the language as its legend. Finally, there are feedforward and feedback relationships between the subsystems and the environment. It is at this level that a paradigm shift (à la Thomas Kuhn) can develop.

__Figure 1 - Our AGI architecture:__  

---
![Figure 1 - Our AGI architecture](images/figure_architecture_small.png)

*In a sequence from left to right:*

- *The world we live in is our context, itself the output of the laws of physics, evolution, etc.*
- *The experiences humans have of this world shape their points of view, which go into a "horizontal" conversation-based documentation-producing process. Here horizontality means every human, or "informant", is considered the same by the system. Or we could say "the system only knows one way to interact with information carrying entities". It is acheived by «unityping», a foundational programming concept. Somewhat counter-intuitively, this is actually a way to ensure the system respects the __diversity__ of points of view coming in.*
- *The work done in conversations outputs a documentation of the world/context, which must obey a rigorous mathematical framework for its internal coherence and interoperability. Every piece of information is "put into a box" (type), where the box serves as "credentials" for the enclosed information to participate in computation. For example '3' can be put in the box 'number' and as a number it can take part in multiplications, which would not be allowed for 'b' in the box 'letters'. Of course the type/box system of our AGI architecture would be much more sophisticated than this, in order to create a computable network of (nearly all) concepts.*
- *This network will be compatible with a model for neural networks suggested by Yuri Manin & Matilde Marcolli. It is at this stage that the architecture exploits the power of neural networks, the machinery behind the latest "AI revolution" of ChatGPT and the likes. As a first step, it can develop a satisfactory AGI "core" by training it on the computable network of concepts. Secondly, it can use this AGI to refine the produced documentation and create new knowledge from existing information.*
- *Eventually this chain of subsystems yields a sort of "interactive map of the world" written in the congruous corpus of documentation, along with a "technical language" which is roughly the collection of types/boxes and their "grammatical rules". Both can have a positive influence on the subsystems preceding them, generating a virtuous feedback loop.*

Note: This article is mostly about subsystems *before* the key neural networks subsystem modelled by Manin & Marcolli. This subsystem is too technical practically and too involved theoretically to be discussed meaningfully in our context.

---

In a sense, every text, drawing or story ever produced can be considered documentation, and I believe it should. Yet, the program I suggest we use for documentation is not meant to be the unique filter through which all production of abstract content must pass, but rather a replicable protocol which confers definite legitimacy to its output, useful in specific cases. Those cases should be considered "open projects", similar in nature to open source projects in computer programming, but applicable to a wider range of activities: open farms, open workshops, open hospitals, etc. (Or without a specific purpose at inception, it would be an "open-ended documentation", and mostly about language itself.) All those projects are grounded on the communal documentation of their concepts, and must be «modular» (interoperable), meaning they must be compatible with, composable with and translatable to and from any other documentation—which is feasible thanks a current revolution in mathematics I'll discuss in the next paragraph. At a project specific level, documentation is locally useful, but it is the assemblage and harmonious concert of documentation which gives our architecture a global significance. As such, they would form a kind of open science in which the systematic encoding of every "interresting/remarkable/unusual thing" extends the inquiry into the proper foundations of mathematics, and vice versa. (See '‘What is a Thing?’: Topos Theory in the Foundations of Physics' by Döring & Isham).

There is a slow and silent revolution happening within the confines of mathematics departments, which "elevates" the rigid framework of «set theory» to the more abstract and flexible «category theory», capable of dealing with ambiguity, redundancy and translations between structures, as explained in figure 2 below. For its advocates, it is an opportunity to encode all scientific concepts into a common language endowed with special properties which reveal and make use of "structural relationships". It has found uses in the conceptualization of computer programs, physics, biology and more, through applied category theory. The mathematics used by current AI implementations are still rooted in the old foundations (it is pretty much the same as the math behind Einstein's general relativity). The model of Manin and Marcolli, on the other hand, uses category theory to its fullest. It takes homotopy types as input and feeds them to groupoid-like neural networks. Our architecture mirrors their model: it uses groupoidal "social" structures to produce concepts encoded in homotopy types, which can then be fed into neural networks.

__Figure 2 - Abstract mathematics for our AGI architecture:__  

--- 
![Figure 2 - Abstract mathematics for our AGI architecture](images/abstract_math.png)

*19th and 20th century set theory is an incredibly powerful mathematical framework upon which all of mathematics was expected to rest, but more recent development have exposed profound inadequacies. Especially the developments introduced by Alexander Grothendieck and used by Manin & Marcolli for their model, and incinditally our architecture.*

1. *This diagram represents a "classic" function f(x) = y, where f "transforms" values of x into values of y, and is representative of set theory. The dots on the left represent the set of all possible values for x, and the arrows point to their corresponding values in the set y according to the function f, the dots on the right. Set theory is mostly about how one forms and thinks about those collections of dots/mathematical objects. While this framework is powerful and perfectly legitimate, I will contend it can't handle the kind of complexity we are targeting.*
1. *This simple diagram represents a «groupoid», which is itself an emanation of a space. It is defined by the provision that all pairs of dots (here: points in space) must be linked by a two-way arrow (here: paths back and forth between the points). I won't go into technical details here and give a general statement to capture the mathematical essence of it: "groupoids are the foundational structure of occupying abstract spaces". In Manin & Marcolli's model they are more or less the neural networks, viewed as "spaces of information". In our architecture they are also used for modelling the documentation-producing conversations, also understood as "spaces of information", taking place between humans, the cognitive resources of the system.*
1. *This more elaborate diagram represents «homotopies» between paths in space (homo = same, topos = place). Granted we have two points in space and two different paths between them, homotopies encode the ways in which one path can be transformed/disformed into the other (possibly none). The essence of it would be: "homotopies are the fundamental structure of describing mathematical objects". Manin & Marcolli follow a beautiful current trend in mathematics and computer science which intends to encode all mathematical objects and their relations into homotopies: «homotopy type theory» (where "type" is the same as our "types as boxes" in the legend of figure 1). In their model, homotopy types are the "food" of the neural networks, what they handle. In our architecture, we ask documentation to be encoded into this language, to be this kind of "food", digestible by "groupoidal" neural networks.*

*A key difference between set theory and the more elaborate structures of groupoids and homotopies is the ability to take into account "ambiguities", redundancies or possible translations between similar enough concepts. Without those, the accumulation of documentation would turn into an impossible mess, whose usefulness would be restricted to very "local" situations and still require the supervision of specialized individuals accustomed to this domain of knowledge—as is currently the case in science and engineering. While this familiarization effort with a local topic is an unavoidable "cost", it can be greatly reduced by the coherent global map of the context/world and the universal technical language which are produced by the AGI architecture, along with the AGI itself.*

---

In pratcice, our AGI architecture insulates a "social" documentation-generating process capable of (i) minimizing assumptions, unnecessary conceptual constraints and false positives "on the input side", and (o) maximizing modularity, composability, reusability, etc. "on the output side". (Later I will propose a 'cell model' inspired by biology.) This is in contrast with the current state of documentation in engineering, for which I list the main issues, tagged with which "side" is affected :

- It is private (o); it is designed and used by private limited companies with their restricted scopes and interests in mind (i).
- The mainstream "philosophical framework" comes from object-oriented programming, which has its advantages but is now considered outdated, especially in this hyper-connected world (o).
- There is no mathematical framework into which information can be encoded, just "naive" illustrations with conventions for recurring concepts (i/o).
- The represented information hardly expands understanding (o); it is rather a form of record keeping for those already "in the know" (i/o).
- Representation of context is usually rudimentary and the isolation of each project makes it impossible to reconstruct a "shared context" (i/o).
- It is largely independent from and incompatible with the academic practice of science—which has its own set of documentation problems, only some of them overlapping with engineering (i/o).

This is also in contrast with the kind of documentation which is "fed" into current implementations of AI, what they are trained on: large datasets, or more generally data science. While this food is cheap and indeed "digestable" by neural networks, and yields the well known results of ChatGPT or DALL-E, it also comes with a number of technical weaknesses and structural problems, most notably political and cultural biases. As with engineering documentation, those are reflecting the issues of the apparatus which generate them: the "wild West" of the internet and its decidedly capitalistic essence (the "com" in .com stands for commercial, not communication), which can only be naively thought of as an emanation of the real world (data science is mainly a branch of marketing, not mathematics). I won't go into the technical details here, and refer the interested reader to Marcolli's critics of LLMs, or large language models, which she presents in her series of lectures 'Mathematical Models of Generative Linguistics' (lectures 17 and 18, freely available online). Her critic is specifically geared towards the *theory* of Large Language Models, which she claims can't apprehend language on a computational level because it was *already* unable to apprehend language on a purely linguistic level.

I will detail the proposed documentation framework below, which includes theoretical foundations, a methodology encoded in a computer program and an expected evolution. Briefly, and in contrast with the list above, its strong point are:

- It is open, and in many ways can be the foundation for an "open source economy".
- Its organization is based on concepts coming from concurrent programming (how to instruct mutliple processes to work in harmony on a single task), especially the "philosophically egalitarian" «actor model». (A slightly different flavor of concurrency is also an important ingredient in Manin & Marcolli's model.)
- It has mathematical foundations which follows and extends Manin & Marcolli's model, as explained above.
- It is a proper implementation of Donald Knuth's idea mentioned above, where one starts with and builds upon documentation of core concepts.
- It must include context and can produce a "panoramic view" via interoperability.
- It can evolve into (1) an AGI system, and (2) a satisfactory form of open science.

Before I go back to the particularities of this implementation, I will explore the genral context into which it is embedded, how it can help understanding it, and how it can "naturally" solve some of its foundational problems.

## AGI as a paradigm shift

In this article I will indeed argue that the emergence of artificial intelligence in human society is an opportunity for timely positive change. Eventually in terms of what it gives, but more immediately—and unexpectedly, in terms of what it requires from us. To do this I will explore and use concepts coming from 4 different cultures, especially where they overlap: practical geeks, theoretical geeks, practical radicals and theoretical radicals. I will give examples of what I mean with each category (which I call by its stereotypical name on purpose, for visibility) but unfortunately they will only be understandable to those with access to the culture. Respectively: Clean Coders, Homotopy Type Theorists, Yellow Vests, Noam Chomsky. If you don't belong to any of them, don't worry, I wrote this article for you. It is by no means a light read, but it is accessible to anyone who will take the time to dig into it. My main goal is to expose the concepts I take from each culture to the "outside world", in order to find consensus on the Artificial General Intelligence system sketched above, which takes human communication as input, includes both a technical and a political side, mirrors foundational structures in mathematics, and which is, contrary to the current paradigm, both efficient and sustainable.

The shift of paradigm concerns the core of our "civilization". Specicifically: specialization, selection, hierarchy, representation. By civilization I mean a social system based on those 4 mechanisms, which I sketch in figure 2 below. In each case the system which implements them loses information and gets corrupted by the social determinism necessarily emerging through competition between individuals (the system "cuts ties" and "misuses ties"). Together they form the main cogs of this fantastic civilization machine running with incredible strength and speed into a doulbe brick wall: (a) the physical limitations of the environment, and (b) its own limitations as a badly designed system. It is set on a collision course with: (A) the planet, because the machine's output is detrimental to the environment it is embedded into, which in turn sends its "negative" output back into the machine (a vicious circle, for details see the theory of dynamical systems, cybernetics or Spinoza); (B) itself, because it confuses "optimal" with "maximal", and indiscriminately exploits all production opportunites regardless of purpose and physical resources. It uses force whenever applicable, all the while wasting/supressing copious amounts of cognitive resources (see the need for manufacturing consent or the wave of professional burn-outs, addictions and many other telling psychological conditions—more generally the cold absurdity of the global economy in the context of imminent global disaster; there is also a hidden part: "mutilations", which I will invoke later).

__Figure 3 - the 4 mechanisms of civilization:__  

---
![Figure 3 - The 4 mechanisms of civilization](images/figure_4_mechanisms_small.png)

*Resources are humans, considered as a cognitive resource. Assignments are when a human is given a type. Types can be a role in the case of specialization: a set of tasks to do in exchange for means of survival/luxury items (which is incredibly empovrished in the case of "scientific management"), a grading in the case of selection: a token giving access to tasks (where most of the wasting of cognitive resources happen and "old assumptions reproduce"), a position in the case of hierarchies: tasks are ordered and with them social status, and in the case of representation: privileges to amend the system.*

*In a sequence from left to right:*

- *Specialization is supposed to be the cornerstone of civilization, the inescapable route to adequate knowledge. It seems evident that an expert will know more than a non-expert, and therefore a system which encourages expertise will know more than a system which does not. I contend this is naive in two ways: (a) humans will specialize whether or not the system encourages them to do so or not, and it is more judicious to let every individual freely decide on their domain and level of experise rather than force it upon them, especially when the "forcing" is based on "where do investments go"; (b) the acknowledgment of experts comes with "hidden costs", in the form of selection, hierarchy and representation, all with detrimental effects on the "cognitive power" of the system (discernible through the framework of «concurrency theory»—the orchestration of multiple processes on a single task: harmonious orchestration is disrupted if one disregards key design principles; in our case that would come to light as "social fricition"). Moreover, experts in a capitalistic economy have an incentive __not__ to share information (you will notice capitalism is copyright-based while open source projects are copyleft-based) and to "cristalize" their thinking and point of view (a fixed idea is easier to sell than an flexible one).*
- *Selection, hierarchies and representation frame the specialization of individuals by enforcing further typing on them. Selection appeared more recently to replace simple heredity and gender based roles (because of the need to fill in key roles in the new industrial economy, notably engineers). Hierarchies serve as control mechanisms on specialized work. Representation used to be amamalgamated with hierarchies, with the top positions being in charge of amending the social system/economy. Now the two mechanisms are separated between private and public sectors, the economy and the nation respectively. (The diagram represent a democracy/oligarchy; a dictatorship would have only one option on the right hand side.)*

*These diagrams are unmistakably set theoretic in nature. Again, our architecture uses diagrams where humans are not assigned a type, or rather are all assigned the same one ("conversionalist"), and only documentation is typed (replacing specialized individuals as "information containers" in the system).*

---

It is quite difficult to argue against the efficiency of civilization. It is almost universally accepted, the common conception is that it saved us from savagery and our base animal instincts—without it we would still be living outdoors and hunting game. It was and still is considered to be the only way "out": it's civilization or chaos (one of the main messages of the epic of Gilgamesh, a foundational myth of civilization). I believe this is ingrained in the collective mind because civilization comes equipped with its own propaganda machine (a consequence of the 4 mechanisms, which are all acts of violence requiring justifications—in many ways civilization started with those justifications, in the temples of Sumer, about 7,500 years ago). It captures any discourse which portrays it in a positive light and turns it into assumptions which "take root" and "mature" in its memory (both elitist and popular culture). It is again allowed and organized by the 4 mechanisms: every time someone climbs up a hierarchy, a legitimation of the hierarchy climbs with them, or every time an advertisment is broadcasted, it implicitely broadcasts a legitimation of the whole system with it. Due to mental shortcuts and biases in epistemology, to criticize civilization is to object science, social contracts, peace among nations and progress in general. (And we humans absolutely need this concept of progress for our psychological survival in such a harsh social system.) While civilization takes all the credit for itself, it also delegates all problems concerning "life in common" to "human nature" (strikingly similar to the logical fallacies infecting an addicited brain, according to Allen Carr—in many ways we are "hooked on" those 4 mechanisms). If ever civilization fails to provide its advertised accomplishments, its advocates will maintain it's not because of its own shortcomings but because it has been mishandled by humans and their *natural* defects. For example, police brutality will not be analyzed on a systemic scale, and the "few bad apples" rethoric is given instead. The fact that our global most pressing social issues can be directly traced back to the 4 mechanisms of civilization doesn't seem to tarnish its reputation (in order of historical emergenece: patriarchy and gender roles, racism and all forms of discrimination, large-scale armed conflicts, class struggle & poverty... the true and inescapable nature of civilization). Again, those issues are often assumed to be intrinsic to human nature (despite the fact that archeology and genetics decidedly proved the contrary, see ⟨hal-02112784⟩). As for obvious structural defects not imputable to human want, such as planned obsolecense, their existence is legitimized by the necessities of capitalism and their effects are largely minimized/ignored. The machine carries on.

*In the interests of space I will not develop a critic of engineering under the influence of the 4 mechanisms and in the service of a palace economy (by palace economy I mean ancient Sumer, Egypt, Rome, etc., as well as the current global economy). I will simply state it: current engineering is "degenerate". It has the same kind of "efficiency" as a cancer cell: it grows, spreads and conquers, but it does so on a way that kills its own environment. (Almost all current research is harnessed for new technologies, and all new technologies are harnessed for new forms of colonialism: of the environment, human minds or abstract concepts.)*

It is even more difficult to argue for an alternative to civilization, since none have been able to withstand its competition, military or otherwise. Almost all survivng human groups have now been colonized one way or another and carry the "4 mechanisms gene/virus". The paths to complexity of alternative social organizations, even when properly studied, have been ignored or misinterpreted, especially in the case of African Egalitarianism (see James Woodburn or the Harvard Kalahari Research Group for details). Even in social theories of evolution, civilization is isolated: there is only one way to human progress (largely taken to be technological progress, behind which looms military and propagandist expension) and it is civilization (largely taken to be the Western world, the top military and propaganda machine). This view has been labeled the "unilineal evolution theory" in the 19th century. Wikipedia claims that "[t]his theory is now generally considered obsolete in academic circles", and while this is probably true, there are no tangible signs of a globally coherent replacement for civilization and its mechnanisms in the scientific litterature (a few exceptions have been incredibly inspiring for my work). Although there are indeed plenty of innitiatives meaning to counter-act the defects of the 4 mechanisms, such as open science or participative democracy, those are considered to be "the next step in civilization" rather than a deep questionning and remodelling of it. The depth of this questioning is approximately measurable in the size, history and "fundamentalness" of the assumptions being questioned. In this light, my critics and recommendations stretch to the bottom of the "political ocean", and will probably appear as "crazy talk" by anyone who doesn't belong to the radical type. But I must include this "radical" political side of the story for the "geeky" technical part to make sense.

Appropriately, the main sources of inspiration for our AGI architecture are all anchored on both sides, "geeky" and "radical":  
(All information retrievable from the respective Wikipedia pages)

- Alexander Grothendieck is the principal architect of the mathematical structures used by Manin & Marcolli for their model of cognitive systems. He also quit his confortable position in the French reserach system on the grounds that it was funded by the military, to start an activism-oriented journal on ecology called "Survivre et vivre". Another important mathematical figure here is Bill Lawvere, who was also a Marxist.

- Noam Chomsky is a linguist and co-author of Marcolli, together they explore the links between mathematical strucutres and "universal grammar", the common core of all human languages. He also identifies as an anarcho-syndicalist or a libertarian socialist.

- Gilles Deleuze is a philosopher who produced a «perspectivalist» framework, in which truth is not absolute as in most philosophical traditions but dependent on a specific point of view; without being totally dependent on it, as in relativism. This perspectivalism can serve as a motivation, or *raison d'être*, for our AGI architecture. Like Grothendieck, Lawvere and Chomsky, he was very close to the 1960s' counter-culture and critical of capitalism and all control mechanisms. A key idea for us would be: "Modern society still suppresses [being] and alienates people from what they can do" ("being" here is an approximation for the more elaborate but semantically confusing concept of "difference").

Rather than "alienation" I would like to use the stronger term of "mutilation" to express the acceptance of one's status and through it the lessening of one's potential. Something Grothendieck also mentions in his 1972 conference 'Allons-nous continuer la recherche scientifique?' at CERN ('Will we continue scientific research?'). This is a direct consequence of the arrows in the diagrams of figure 3, where a human cognitive resource is assigned a type. Our AGI architecture proposes an alternative in which those arrows are absent and replaced with more elaborate and "horizontal" mathematical stucutres. This will safeguard individual freedom and through it "communities of attachment". Attachment theory is a psychological and evolutionary framework concerning the relationships between humans, particularly the importance of early bonds between infants and their primary caregivers. It can be abstracted away in a simple and "continous" algorithm of networks:

1. The network of existing elements allows new elements to develop adequately (element ← nurture).
2. Adequately developed elements form a network capable of helping a new generation of elements to develop (element → nurture).

Eventually, I will argue that the preservation of the autonomy and "naturalness" of this algorithm is ultimately what is at stake for the sustainability of humanity's social system and with it, its context/environment (crucially, autonomy and naturalness here imply not imposing any preconceptions on what "adequately" means). It can be acheived because the mathematical structures on which our AGI architecture is grounded can be interpreted in this attachment framework as conversation (groupoid) and empathy (homotopy), two major factors/mechanisms in the formation of "communities of attachement". In many ways, high complexity seems to require this kind of sophistication in the design of network architectures, if such networks are to exploit this complexity for computation, cognition, understanding, etc.

## (Mathematical) naturality of the suggested documentation framework

In its "geeky" incarnation, the suggested AGI system is a form of open science with computability capabilities, where open means science without selection of individuals/cognitive resources (which is not the same as science without truth criteria, similar to how perspectivalism is not relativism), and computability refers to its artificial intelligence side, its ability to derive extra knowledge from existing knowledge. In its "radical" incarnation it is a resistance network enabling the creation of autonomous communities, occupying new abstract spaces and based on different principles than the 4 mechanisms of civilization (not a reform of the existing system, not a revolution wanting to take it down, but a process which *creates its own space*, as I will explain more in details below). These two incarnations are co-dependent: communities need complexity/science for sustainable growth, while complexity itself needs communities to create adequate spaces in which it can emerge.

I won't compare civilization and our documentation-powered AGI system point by point, but focus on those three aspects: (1) people are ready for it, (2) it's accessible, and (3) as a solution it is "natural" in a mathematical sense.

1. People are ready for the paradigm shift and demonstrated their willingness to look for collective structures outside the 4 mechanisms during the wave of popular protests of the period 2018-2019 (see 'The age of mass protests' by Brannen, Haig & Schmidt for a factual recap). In 40 different countries, movements emerged with unmistakable common traits, which all have to do with the *negation* of the 4 mechanisms. They didn't have:

    - representation: the movements were decidedly "bottom up" or "grassroots", and rarely had public figures as leaders.
    - hierarchy: the movements had horizontal/diffuse internal structure.
    - selection: the aim of the movement, or rather its *raison d'être*, was not defined in advance.

    What conditioned adhesion was not a specific set of held beliefs but the organizational philosophy of the movement. While their influence on the collective mindset was certain (but largely wiped off by the Covid crisis which directly followed), their actions didn't amount to anything concrete and durable: they never *specialized* to anything which could become an acceptable member of the body of institutions, such as a union or political party. They would have had to renounce their organizational and philosophical principles to do so, and did not. As such they exhibited a new form of practical "societal maturity"—they were truly florishing practical radicals, but without enough theoretical "political maturity" to turn their spontaneous movements into the structures adapted to their philosophy. (The only existing political structure compatible with it are citizen assemblies, which I will use as the "base module" for the documentation procedure explained below. Those have been well tested since their first implementations in the 1990s and have always generated satisfactory results.) On a psychological level, those movements were also experienced as a break away from alienation/mutilations and a return to non-institutionalized communities .

    *Note: At this point I would like to indicate that I first thought about this architecture as an engineer of human communication systems, inspired by the beauty of such movements. I then proceeded to find it a mathematical model, which I found in Grothendieck & Lawvere mathematics, and only recently did I find out about the same model in Manin & Marcolli's cognitive systems (to some extent, this overlap and compatibility validates my research up to this point). In order to widen my understanding of the architecture and its context, I used the theoretical bidges of category theory and the practical principles of the implementation to make forays into other domains of inquiry (philosophy, physics, biology, as well as humanities). The next step was to find the most compact abstractions, algorithms, diagrams, etc. and eventually present the most interesting and convincing aspects in a relatively short article with manageable complexity.*

1. The implementation of the architecture is accessible because it will *indirectly* replace the 4 mechanisms with new structures coming *directly* from the foundations of mathematics.

    A crucial «design principle» of our AGI architecture, which is mandated by the mathematical structure, is clear separation between reality (≅ "where we do life") and the abstract (≅ "where we do language"). As explained in figure 4 below, every project following this architecture should be "insulated" and (1) have as little associations with reality as possible, and (2) manage its own language. It is this principle which induces the creation of a new space. It confers lots of advantages to the abstract module (what emerges in the new space), but also to reality itself, which is protected from a possibly detrimental influence from the abstract realm. For instance:

    - AI systems are safe (no mechanical leverrage of AI in reality, no AI takeover possible, no global schizophrenia/loss of sense of reality, etc.)
    - Without a "broacasting aparatus" in reality, the abstract module can't generate interferences such as advertising/marketing/lobbying/... and other opinion & moral compass influences.
    - Freedom of work can be granted with enough open projects working on sufficiently elaborate open documentation.  

   This «separation of concerns» also makes the implementation of the architecture easy. (For a "translation" of this story in "practical geek" lingo, see 'Typed dataspace actors' by Caldwell, Garnock-Jones and Felleisen, where actors are our "egalitarian" cognitive resources and the typed dataspace is our new abstract space).

    - Because the replacement is indirect, there is no need to modify existing structures. The new paradigm will emerge in an abstract space made of thought, language, computer code, mathematical structures and their complex documentation. This space will be new: it will start empty and only allow information to come in according to a unique protocol for all "informants" (humans in conversations) and following some «type theory» for coherence. See figure 4 below: the "cell model" of new abstract spaces. Both the initial emptiness and the uniqueness of the protocol are filters/safeguards against the introduction of assumptions/false postivies into the new space. (Interestingly, they are also in direct conflict, meaning that they are mutually exclusive, with the 4 mechanisms of civilization, which require assumptions as "dependencies": the assignement of the initial body of experts and managers of future assignments.) As developed above, this homotopy-based abstract space is expected to evolve into a complex and multidimensional network of concepts which could be viewed as a map of the informants' context, our world, or as a "universal technical language" (a language purposefully designed for science and engineering, with managable complexity thanks to homotopies and extremely useful for our "life in common" problems). These new spaces and their documentation are the emanation of the "horizontality" of the protocol and can act as "abstract managers" for open projects, the instances of open science and an open source economy. Once they are sufficiently mature, they will offer an efficient and sustainable alternative to the current global economy.

    - Because the base concepts are mathematical stuctures and they only require some computer code and internet access to run, the costs of implementation are very cheap. The system is moreover totally autonomous, without control mechanisms, without managers. As we've seen, people are ready for such organizations, so we can expect spontaneous interest and participation. The concept only waits for its recognition and legitimation to start and grow. (Its parts are all legetimate concepts in the eyes of the research community already, but the combination of them is not yet discussed in the scientific litterature. (I found a glimpse of it in 'Social Machines for All' by Papapanagiotou & al.)

    See figure 5 below for a quick overview of how our AGI architecture can be "plugged into" open source projects, creating a network—an open source economy, which can in turn fuel autonomous communities without the need to resort to the 4 mechanisms.

    __Figure 4 - The "cell model" of new abstract space__

    ---
    ![Figure 4 - The "cell model" of new abstract space](images/scan-cell-model-legend-small.png)

    *The cell we imagine here is a metaphor for an open project whose purpose is to create a technical language for mathematics, science, engineering and the arts, with two main criteria in mind: (1) low entry costs for humans (pedagogical), which importantly includes reuse of concepts across domains—a "versatile base toolkit of core concepts", and (2) the ability to deal with high complexity. (Both challenges would be met with heavy use of homotopy type theory.)*  
    *This new language would be considered the "new abstract space" in this case.*  
    *I choose this example because it is where a network of such open projects should start, by managing its own language. As a "language creating unit", it can be thought of as a sort of stem cell, something that could later be duplicated and used as a basis for more specific purposes.*  

    *Following the numbering on the diagram:*

    1. _Reality, or the context/environment. For the metaphoric cell that would be a soup of molecules, and parameters such as pressure, temperature, etc. For the open project that would be our shared human context, whose "atomic constituents" are information/knowledge/concepts._
    1. _The cell wall which delineates what is the "new abstract space" on the interior and what is its environment/context on the outside, is a design principle known as «separation of concerns» which states that the two sectors should have as little "connections" as possible. This is vacuously true on the side of the new space before it comes to existence. The difficulty lies in the insulation of this space from reality. Fortunately, this is already what language, logic or mathematics do "naturally", so they can be included. Inversely, people's lives, buildings, money, etc. must be excluded._
    1. _The cell wall has a "protocol" which regulates how information comes in. This is carried out by a distributed computer program. This protocol is the subject of the next section, but in brief, it is a network of conversations, where conversations act as "filters" collecting and refining information coming from outside the cell wall. (Conversations are modelled on the concept of citizen assemblies in participative democracy). As for the "actual thing" running the program which generates the space, it operates by "reversing dependencies": it states what it needs (very little) and it simply expects those needs to be met, without any form of interference or compensation. (Technically, it should be like a torrent network.)_
    1. _This computer program acts as a genome, it has a starting kit of document types and gives a procedure to produce documented concepts. Those are the "proteins", or working units of the open project, what determine its "state" and "function". (In this metaphor, humans act as catalysts or chaperones.)_
    1. _The produced documentation is the cell. If it is indeed compatible with others, as required by the mathematical structure but also enabled by the same mathematical structure, cells can form organisms. In our case, an open science and an open source economy._

    ---

    __Figure 5 - An overview of open source economy__

    ---
    ![Figure 5 - An overview of open source economy](images/scan-open-eco.png)

    *legend*

    ---

1. The notion of "naturality" in mathematics comes in two flavours. There is a technical and formaly defined concept which applies to "transformation between mathematical structures" in the most abstract branch of mathematics—the "home" for our AGI architecture: category theory (which actually started in the 1940s with this very notion, see Eilenberg & Mac Lane). Naturality is here akin to the "types as boxes" metaphore above: objects which can be put in the box labelled "natural transformations" have special mathematical properties and can participate in interesting operations. I will not develop them here. I will instead rely upon the other flavour: naturality as an informal, qualitative judgement on solutions to problems. For a quick example, see Yuri Manin's interview for the Simons Foundation, when he talks about Alexander Grothendieck. Also, I will generalize the mathematical context to problems in general, including engineering, philosophy, etc. A solution can be characterized as natural if:

    - It is universal, in the sense that it can be applied in many, possibly quite different situations.
    - It is simple, but not necessarily obvious. It might take effort to see how a simple operation will produce the desired effects. While the solution is indeed simple to comprehend, it can still require effort for the understanding of the problem and its context, for *how* it is a solution for it. This happened to a beautiful and remarkably universal mathematical structure called a topos, introduced by Alexander Grothendieck—by his own admition the most important of his creations, whose potential is taking a very long time to develop in the hands of others. Because despite the accessibility of the formal definition, understanding its usefulness requires seeing it from a specific perspective, which is not "obvious" for most mathematician. (It breaks with established conventions, uses an unfamiliar methodology, and in many ways solves problems mathematicians don't know they have.)
    - It manages complexity. If we understand a solution to be a certain perspective on a problem and the course of action this viewpoint entails (following C. S. Peirce's pragmaticist maxim), the solution can "lose" complexity by truncating the problem and only partially or inadequately resolving the situation. But it can also tame complexity if the perspective preserves what is important and useful in a "compressed" version of the situation (this is encoded in category theory by the notion of «limit»). At this point a natural solution can emerge.
    - It is a "plateau of understanding", below which operational details can be safely forgotten, and upon which one can build further understanding, cognition, new tools, etc.

    I believe our AGI architecture meets those criterias.

    - The scope is broad: It is a solution to the problems of "life in common" or "parralel processing" for information carrying entities endowed with language.
    - It uses only a handful of core concepts and makes repeated use of them, to build a structure that can scale up gracefully (notably groupoids and homotopies). If it is not obviously a solution as of yet, it is due to deeply rooted assumptions about how a social system gains cognitive power (namely, it supposedly requires the 4 mechanisms of civilization).
    - At the most general level ("up"), if our AGI architecture is indeed a valid solution, this suggests a seducing perspective on Nature which I haven't exposed here: a generalized theory of evolution "by coverings", where every step in the evolutionary process must "map/triangulate its world" and in doing so allows a new and unexpected systems to emerge. See figure 6 below. Operationaly ("down"), with the mathematical notion of homotopy (encoding how two "transformations" are equivalent), the documentation process can efficiently and indefinitely compress its content and organize it in appropriate levels of details.
    - Importantly, while it is in iteslf a natural solution, it is also a methodology to find more. It is the "collective" counterpart of the "individual" scientific method, whose scope/domain of application is restricted to individual examiners and their direct relationship to Nature. The 4 mechanisms of civilization use the scientific method but the assignement of roles also restricts it to its individual incarnation, while our AGI architecture properly enables a collective examination, mobilizing a *shared* relationship to Nature.

Figure 6 - An overview of a generalized theory of evolution by coverings

---
![Figure 6 - An overview of a generalized theory of evolution by coverings](images/figure_evolution_by_coverings.png)

> *legend*

---

## The documentation process

I will first give a very brief and necessarily truncated factual description of the system, then complement it with subsections in a Frenquently Asked Questions format.

### -      -

#### What is a conversation?

staffing, prerogatives

### --     -

#### How does the system "refine" information?

1. The system doesn't "collect" information from experts directly but make use of a special entity which we can call the "random person". (expert -pedagogy-> random ; many -participation-> random ; many <-tech lang mastery-> expert)

How does interoperbality work? How can we put all content into one big network of concepts?
Thing -model-> mathematical object ; for all mathematical object we can ask what is its homotopy types, every pair of homotopy types can be compared.

Who writes the programs?
volunteers

Who runs the programs?
benevolent entities

## Return to (generalized) mother

{I didn't say: derives into notions of perspectivalis... ...and has origins in "egalitarian mythology", because I would have instantly lost all credibility, but this passage, representative of a corpus of testimonies and their analysis is quite telling -> quote (replace nugget with "pivotal concept"). It is a dense network of concepts, exactly what we need if we are to recover our "evolutionary path".}

Define trust, and how our AGI architecture is the most trustable system possible, because it is also the most "horizontal" (no assumptions).

---

---

---

Figures:

- groupoids and homotopies
- cell model of new abstract spaces
- open source economy

« » —

